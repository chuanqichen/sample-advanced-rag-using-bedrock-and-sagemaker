{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c01279f-f6b3-46a2-9c76-ecf34f9dc275",
   "metadata": {},
   "source": [
    "## Create a Knowledge Base with Semantic chunking strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e0a202-87f1-4a0f-9d2f-e697e6b98bee",
   "metadata": {},
   "source": [
    "#### Concept\n",
    "\n",
    "Semantic chunking analyzes the relationships within a text and divides it into meaningful and complete chunks, which are derived based on the semantic similarity calculated by the embedding model. This approach preserves the information’s integrity during retrieval, helping to ensure accurate and contextually appropriate results. Knowledge Bases for Amazon Bedrock first divides documents into chunks based on the specified token size. Embeddings are created for each chunk, and similar chunks in the embedding space are combined based on the similarity threshold and buffer size, forming new chunks. Consequently, the chunk size can vary across chunks.\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "* By focusing on the text’s meaning and context, semantic chunking significantly improves the quality of retrieval. It should be used in scenarios where maintaining the semantic integrity of the text is crucial.\n",
    "\n",
    "* Although this method is more computationally intensive than fixed-size chunking, it can be beneficial for chunking documents where contextual boundaries aren’t clear—for example, legal documents or technical manuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9e7a2e-6062-4171-85ae-e78c06f2c50b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accountNumber': '307297743176',\n",
       " 'regionName': 'us-west-2',\n",
       " 'collectionArn': 'arn:aws:aoss:us-west-2:307297743176:collection/h7cmj732p9d3v91spkhd',\n",
       " 'collectionId': 'h7cmj732p9d3v91spkhd',\n",
       " 'vectorIndexName': 'ws-index-',\n",
       " 'bedrockExecutionRoleArn': 'arn:aws:iam::307297743176:role/advanced-rag-workshop-bedrock_execution_role-us-west-2',\n",
       " 's3Bucket': '307297743176-us-west-2-advanced-rag-workshop',\n",
       " 'kbFixedChunk': '4P6PBDDEGL',\n",
       " 'kbSemanticChunk': 'IC3ZCBORXT'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805c37f-2e62-4945-b0e3-05af7db0e60d",
   "metadata": {},
   "source": [
    "### 1. Create a Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271e876a-6043-40f6-8ba1-31f39b474409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helper function definition\n",
    "from retrying import retry\n",
    "import boto3\n",
    "\n",
    "# Initialize the Bedrock agent client with the specified region\n",
    "bedrock_agent = boto3.client(\"bedrock-agent\", region_name=variables[\"regionName\"])\n",
    "\n",
    "@retry(wait_random_min=1000, wait_random_max=2000, stop_max_attempt_number=3)\n",
    "def create_knowledge_base_func(name, description, chunking_type):\n",
    "    # The embedding model used by Bedrock to embed ingested documents and real-time prompts\n",
    "    embedding_model_arn = f\"arn:aws:bedrock:{variables['regionName']}::foundation-model/amazon.titan-embed-text-v2:0\"\n",
    "    \n",
    "    # Configuration for OpenSearch Serverless to store vectors and associated metadata\n",
    "    opensearch_serverless_configuration = {\n",
    "            \"collectionArn\": variables[\"collectionArn\"],  # ARN for the OpenSearch collection\n",
    "            \"vectorIndexName\": variables[\"vectorIndexName\"] + chunking_type,  # Vector index name appended with chunking type\n",
    "            \"fieldMapping\": {  # Mapping the fields for vector, text, and metadata\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Printing the configuration to verify before creating the Knowledge Base\n",
    "    print(opensearch_serverless_configuration)\n",
    "    \n",
    "    # Create the Knowledge Base using Bedrock Agent's API\n",
    "    create_kb_response = bedrock_agent.create_knowledge_base(\n",
    "        name=name,  # Knowledge base name\n",
    "        description=description,  # Knowledge base description\n",
    "        roleArn=variables[\"bedrockExecutionRoleArn\"],  # IAM role ARN for Bedrock to assume\n",
    "        knowledgeBaseConfiguration={  # Configuration for the knowledge base\n",
    "            \"type\": \"VECTOR\",  # Type of Knowledge Base: VECTOR for vectorized data\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embedding_model_arn  # ARN for the embedding model\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration={  # Storage configuration for the knowledge base\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",  # Using OpenSearch Serverless as the storage option\n",
    "            \"opensearchServerlessConfiguration\": opensearch_serverless_configuration  # OpenSearch configuration details\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Return the created knowledge base details\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5811c00f-1c67-4cb9-8a91-13a3690d54ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collectionArn': 'arn:aws:aoss:us-west-2:307297743176:collection/h7cmj732p9d3v91spkhd', 'vectorIndexName': 'ws-index-semantic', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "{'collectionArn': 'arn:aws:aoss:us-west-2:307297743176:collection/h7cmj732p9d3v91spkhd', 'vectorIndexName': 'ws-index-semantic', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "{'collectionArn': 'arn:aws:aoss:us-west-2:307297743176:collection/h7cmj732p9d3v91spkhd', 'vectorIndexName': 'ws-index-semantic', 'fieldMapping': {'vectorField': 'vector', 'textField': 'text', 'metadataField': 'text-metadata'}}\n",
      "Knowledge Base already exists. Retrieving its ID...\n",
      "Found existing knowledge base with ID: IC3ZCBORXT\n",
      "OpenSearch Knowledge Response: {\n",
      "    \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"901a32ac-6a3d-41ed-9a2b-d8a8a149fec0\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "            \"date\": \"Mon, 07 Apr 2025 15:43:43 GMT\",\n",
      "            \"content-type\": \"application/json\",\n",
      "            \"content-length\": \"960\",\n",
      "            \"connection\": \"keep-alive\",\n",
      "            \"x-amzn-requestid\": \"901a32ac-6a3d-41ed-9a2b-d8a8a149fec0\",\n",
      "            \"x-amz-apigw-id\": \"IqLbeHIEvHcEiEA=\",\n",
      "            \"x-amzn-trace-id\": \"Root=1-67f3f2af-387ce135040109e05aa2e9cf\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "    },\n",
      "    \"knowledgeBase\": {\n",
      "        \"createdAt\": \"2025-04-07 15:38:00.426922+00:00\",\n",
      "        \"description\": \"Knowledge base using Amazon OpenSearch Service as a vector store\",\n",
      "        \"knowledgeBaseArn\": \"arn:aws:bedrock:us-west-2:307297743176:knowledge-base/IC3ZCBORXT\",\n",
      "        \"knowledgeBaseConfiguration\": {\n",
      "            \"type\": \"VECTOR\",\n",
      "            \"vectorKnowledgeBaseConfiguration\": {\n",
      "                \"embeddingModelArn\": \"arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0\"\n",
      "            }\n",
      "        },\n",
      "        \"knowledgeBaseId\": \"IC3ZCBORXT\",\n",
      "        \"name\": \"advanced-rag-workshop-semantic-chunking\",\n",
      "        \"roleArn\": \"arn:aws:iam::307297743176:role/advanced-rag-workshop-bedrock_execution_role-us-west-2\",\n",
      "        \"status\": \"ACTIVE\",\n",
      "        \"storageConfiguration\": {\n",
      "            \"opensearchServerlessConfiguration\": {\n",
      "                \"collectionArn\": \"arn:aws:aoss:us-west-2:307297743176:collection/h7cmj732p9d3v91spkhd\",\n",
      "                \"fieldMapping\": {\n",
      "                    \"metadataField\": \"text-metadata\",\n",
      "                    \"textField\": \"text\",\n",
      "                    \"vectorField\": \"vector\"\n",
      "                },\n",
      "                \"vectorIndexName\": \"ws-index-semantic\"\n",
      "            },\n",
      "            \"type\": \"OPENSEARCH_SERVERLESS\"\n",
      "        },\n",
      "        \"updatedAt\": \"2025-04-07 15:38:00.426922+00:00\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Create a knowledge base using the predefined function\n",
    "    kb = create_knowledge_base_func(\n",
    "        name=\"advanced-rag-workshop-semantic-chunking\",\n",
    "        description=\"Knowledge base using Amazon OpenSearch Service as a vector store\",\n",
    "        chunking_type=\"semantic\"\n",
    "    )\n",
    "\n",
    "    # Retrieve details of the newly created knowledge base\n",
    "    get_kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb['knowledgeBaseId'])\n",
    "\n",
    "    # Update the variables dictionary with the new knowledge base ID\n",
    "    variables[\"kbSemanticChunk\"] = kb['knowledgeBaseId']\n",
    "\n",
    "    # Save updated variables to a JSON file, handling datetime serialization\n",
    "    with open(\"variables.json\", \"w\") as f:\n",
    "        json.dump(variables, f, indent=4, default=str)  # Convert datetime to string\n",
    "\n",
    "    # Print the retrieved knowledge base response in a readable format\n",
    "    print(f'OpenSearch Knowledge Response: {json.dumps(get_kb_response, indent=4, default=str)}')\n",
    "    \n",
    "except Exception as e:\n",
    "    # Check if error message indicates the knowledge base already exists\n",
    "    error_message = str(e).lower()\n",
    "    if any(phrase in error_message for phrase in [\"already exist\", \"duplicate\", \"already been created\"]):\n",
    "        print(\"Knowledge Base already exists. Retrieving its ID...\")\n",
    "        \n",
    "        # List all knowledge bases to find the one that already exists\n",
    "        list_kb_response = bedrock_agent.list_knowledge_bases()\n",
    "        \n",
    "        # Look for a knowledge base with the desired name\n",
    "        for kb in list_kb_response.get('knowledgeBaseSummaries', []):\n",
    "            if kb['name'] == \"advanced-rag-workshop-semantic-chunking\":\n",
    "                kb_id = kb['knowledgeBaseId']\n",
    "                print(f\"Found existing knowledge base with ID: {kb_id}\")\n",
    "                \n",
    "                # Get the details of the existing knowledge base\n",
    "                get_kb_response = bedrock_agent.get_knowledge_base(knowledgeBaseId=kb_id)\n",
    "                \n",
    "                # With this code that reads existing values first:\n",
    "                try:\n",
    "                    # Read existing variables\n",
    "                    with open(\"variables.json\", \"r\") as f:\n",
    "                        existing_variables = json.load(f)\n",
    "                except (FileNotFoundError, json.JSONDecodeError):\n",
    "                    # If file doesn't exist or is invalid JSON\n",
    "                    existing_variables = {}\n",
    "                \n",
    "                # Update only the semantic chunking value\n",
    "                existing_variables[\"kbSemanticChunk\"] = kb_id\n",
    "                                \n",
    "                # Write back all variables\n",
    "                with open(\"variables.json\", \"w\") as f:\n",
    "                    json.dump(existing_variables, f, indent=4, default=str)\n",
    "                \n",
    "                # Print the retrieved knowledge base response\n",
    "                print(f'OpenSearch Knowledge Response: {json.dumps(get_kb_response, indent=4, default=str)}')\n",
    "                break        \n",
    "        else:\n",
    "            print(\"Could not find a knowledge base with the specified name.\")\n",
    "    else:\n",
    "        # If it's a different error, re-raise it\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfebc0-bdeb-4f43-a0a0-921d34be6aba",
   "metadata": {},
   "source": [
    "### 2. Create Datasources for Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52912279-14aa-4817-8b33-f8e8786a9a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing data source 'advanced-rag-example'. Deleting it...\n",
      "Waiting for data source deletion to complete...\n",
      "Data source deleted successfully.\n",
      "Creating new data source 'advanced-rag-example' with semantic chunking...\n",
      "Semantic chunking data source created successfully.\n",
      "{'createdAt': datetime.datetime(2025, 4, 7, 15, 43, 54, 302485, tzinfo=tzlocal()), 'dataDeletionPolicy': 'DELETE', 'dataSourceConfiguration': {'s3Configuration': {'bucketArn': 'arn:aws:s3:::307297743176-us-west-2-advanced-rag-workshop', 'inclusionPrefixes': ['data']}, 'type': 'S3'}, 'dataSourceId': 'I7WFEFDWJN', 'description': 'A data source for Advanced RAG workshop', 'knowledgeBaseId': 'IC3ZCBORXT', 'name': 'advanced-rag-example', 'status': 'AVAILABLE', 'updatedAt': datetime.datetime(2025, 4, 7, 15, 43, 54, 302485, tzinfo=tzlocal()), 'vectorIngestionConfiguration': {'chunkingConfiguration': {'chunkingStrategy': 'SEMANTIC', 'semanticChunkingConfiguration': {'breakpointPercentileThreshold': 95, 'bufferSize': 1, 'maxTokens': 300}}}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Define the chunking strategy configuration for semantic chunking\n",
    "chunking_strategy_configuration = {\n",
    "    \"chunkingStrategy\": \"SEMANTIC\",  # Using semantic chunking strategy\n",
    "    \"semanticChunkingConfiguration\": {\n",
    "        \"maxTokens\": 300,  # Maximum token length per chunk\n",
    "        \"bufferSize\": 1,   # Buffer size to handle context overlap between chunks\n",
    "        \"breakpointPercentileThreshold\": 95  # Percentile threshold for breaking chunks\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configuration for the data source with inclusion prefix\n",
    "s3_configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{variables['s3Bucket']}\",\n",
    "    \"inclusionPrefixes\": [\"data\"]  # Only include objects with the \"data\" prefix\n",
    "}\n",
    "\n",
    "data_source_name = \"advanced-rag-example\"\n",
    "\n",
    "# First, check if a data source with this name already exists in Bedrock\n",
    "try:\n",
    "    # List all data sources for the knowledge base\n",
    "    list_ds_response = bedrock_agent.list_data_sources(\n",
    "        knowledgeBaseId=kb['knowledgeBaseId']\n",
    "    )\n",
    "    \n",
    "    # Check if our named data source exists\n",
    "    existing_ds = None\n",
    "    for ds in list_ds_response.get('dataSourceSummaries', []):\n",
    "        if ds['name'] == data_source_name:\n",
    "            existing_ds = ds\n",
    "            break\n",
    "    \n",
    "    # If it exists, delete it\n",
    "    if existing_ds:\n",
    "        print(f\"Found existing data source '{data_source_name}'. Deleting it...\")\n",
    "        bedrock_agent.delete_data_source(\n",
    "            knowledgeBaseId=kb['knowledgeBaseId'],\n",
    "            dataSourceId=existing_ds[\"dataSourceId\"]\n",
    "        )\n",
    "        print(\"Waiting for data source deletion to complete...\")\n",
    "        time.sleep(10)\n",
    "        print(\"Data source deleted successfully.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error while checking or deleting data source: {e}\")\n",
    "\n",
    "# Now create a new data source\n",
    "try:\n",
    "    print(f\"Creating new data source '{data_source_name}' with semantic chunking...\")\n",
    "    create_ds_response = bedrock_agent.create_data_source(\n",
    "        name=data_source_name,\n",
    "        description=\"A data source for Advanced RAG workshop\",\n",
    "        knowledgeBaseId=kb['knowledgeBaseId'],\n",
    "        dataSourceConfiguration={\n",
    "            \"type\": \"S3\",\n",
    "            \"s3Configuration\": s3_configuration\n",
    "        },\n",
    "        vectorIngestionConfiguration={\n",
    "            \"chunkingConfiguration\": chunking_strategy_configuration\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Store the created data source object\n",
    "    ds_semantic_chunk = create_ds_response[\"dataSource\"]\n",
    "    print(f\"Semantic chunking data source created successfully.\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ConflictException':\n",
    "        print(f\"Data source '{data_source_name}' still exists. Retrieving it...\")\n",
    "        # Get the existing data source\n",
    "        list_ds_response = bedrock_agent.list_data_sources(\n",
    "            knowledgeBaseId=kb['knowledgeBaseId']\n",
    "        )\n",
    "        for ds in list_ds_response.get('dataSourceSummaries', []):\n",
    "            if ds['name'] == data_source_name:\n",
    "                ds_semantic_chunk = ds\n",
    "                print(f\"Retrieved existing data source: {ds['dataSourceId']}\")\n",
    "                break\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# Print the data source information\n",
    "print(ds_semantic_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d415f-d61f-49ae-9d9a-1ea3063a1452",
   "metadata": {},
   "source": [
    "### 3. Start Ingestion Job for Amazon Bedrock Knowledge base pointing to Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cc69d",
   "metadata": {},
   "source": [
    "> **Note**: The ingestion process will take approximately 2-3 minutes to complete. During this time, the system is processing your documents by:\n",
    "> 1. Extracting text from the source files\n",
    "> 2. Chunking the content according to the defined strategy (Fixed / Semantic / Hierachical / Custom)\n",
    "> 3. Generating embeddings for each chunk\n",
    "> 4. Storing the embeddings and associated metadata in the OpenSearch vector database\n",
    ">\n",
    "> You'll see status updates as the process progresses. Please wait for the \"Ingestion job completed successfully\" message before proceeding to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c945b5-f64b-4e8a-a290-f9ab2d603304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion job started successfully\n",
      "\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "running...\n",
      "Job completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# List to store ingestion jobs\n",
    "ingest_jobs=[]\n",
    "\n",
    "# Start an ingestion job for the given data source and knowledge base\n",
    "try:\n",
    "    # Initiate the ingestion job and capture the response\n",
    "    start_job_response = bedrock_agent.start_ingestion_job(\n",
    "        knowledgeBaseId = kb['knowledgeBaseId'],  # Knowledge base ID\n",
    "        dataSourceId = ds_semantic_chunk[\"dataSourceId\"]  # Data source ID\n",
    "    )\n",
    "    job = start_job_response[\"ingestionJob\"]  # Retrieve the ingestion job details\n",
    "    print(f\"Ingestion job started successfully\\n\")\n",
    "\n",
    "    # Monitor the ingestion job status until it completes\n",
    "    while(job['status'] != 'COMPLETE'):\n",
    "        # Sleep for a brief period to ensure the job is fully completed\n",
    "        print(\"running...\")\n",
    "        time.sleep(10)\n",
    "        # Check the status of the ingestion job\n",
    "        get_job_response = bedrock_agent.get_ingestion_job(\n",
    "            knowledgeBaseId = kb['knowledgeBaseId'],\n",
    "            dataSourceId = ds_semantic_chunk[\"dataSourceId\"],\n",
    "            ingestionJobId = job[\"ingestionJobId\"]  # Use the ingestion job ID to fetch the status\n",
    "        )\n",
    "        job = get_job_response[\"ingestionJob\"]  # Update the job status\n",
    "\n",
    "    print(f\"Job completed successfully\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors that occur during the job start process\n",
    "    print(f\"Couldn't start job.\\n\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988051f4-2741-4180-af71-d445f2eaf37d",
   "metadata": {},
   "source": [
    "### 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3daeb341-cfa4-4c90-9f0d-162e047962e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"Dollar is as follows (in millions): Year Ended December 31, 2022 Year Ended December 31, 2023 \\n \\n  \\n \\n As Reported \\n \\n Exchange Rate \\n \\n Effect (1) \\n \\n At Prior Year \\n \\n Rates (2) As \\n \\n Reported \\n \\n Exchange Rate \\n \\n Effect (1) \\n \\n At Prior Year \\n \\n Rates (2) \\n \\n Net sales $ 513,983 $ 15,495 $ 529,478 $ 574,785 $ 71 $ 574,856 Operating expenses 501,735 16,356 518,091 537,933 531 538,464 Operating income 12,248 (861) 11,387 36,852 (460) 36,392 \\n \\n ___________________ (1) Represents the change in reported amounts resulting from changes in foreign exchange rates from those in effect in the comparable prior year period for \\n \\n operating results. (2) Represents the outcome that would have resulted had foreign exchange rates in the reported period been the same as those in effect in the comparable prior \\n \\n year period for operating results. \\n \\n 30Table of Contents \\n \\n Guidance \\n \\n We provided guidance on February 1, 2024, in our earnings release furnished on Form 8-K as set forth below. These forward-looking statements reflect Amazon.com\\u2019s expectations as of February 1, 2024, and are subject to substantial uncertainty.\",\n",
      "  \") 99,025 (3,040) 113,618 201,875 Net income \\u2014 \\u2014 \\u2014 \\u2014 \\u2014 59,248 59,248 Other comprehensive income (loss) \\u2014 \\u2014 \\u2014 \\u2014 3,006 \\u2014 3,006 Stock-based compensation and issuance of employee benefit plan stock 210 2 \\u2014 21,839 \\u2014 \\u2014 21,841 Balance as of December 31, 2024 10,593 $ 111 $ (7,837) $ 120,864 $ (34) $ 172,866 $ 285,970 \\n \\n See accompanying notes to consolidated financial statements. \\n \\n 40Table of Contents \\n \\n AMAZON.COM, INC. NOTES TO CONSOLIDATED FINANCIAL STATEMENTS \\n \\n Note 1 \\u2014 DESCRIPTION OF BUSINESS, ACCOUNTING POLICIES, AND SUPPLEMENTAL DISCLOSURES \\n \\n Description of Business \\n \\n We seek to be Earth\\u2019s most customer-centric company.\",\n",
      "  \"Dollar is as follows (in millions): Year Ended December 31, 2023 Year Ended December 31, 2024 \\n \\n  \\n \\n As Reported \\n \\n Exchange Rate \\n \\n Effect (1) \\n \\n At Prior Year \\n \\n Rates (2) As \\n \\n Reported \\n \\n Exchange Rate \\n \\n Effect (1) \\n \\n At Prior Year \\n \\n Rates (2) \\n \\n Net sales $ 574,785 $ 71 $ 574,856 $ 637,959 $ 2,335 $ 640,294 Operating expenses 537,933 531 538,464 569,366 2,466 571,832 Operating income 36,852 (460) 36,392 68,593 (131) 68,462 \\n \\n ___________________ (1) Represents the change in reported amounts resulting from changes in foreign exchange rates from those in effect in the comparable prior year period for \\n \\n operating results. (2) Represents the outcome that would have resulted had foreign exchange rates in the reported period been the same as those in effect in the comparable prior \\n \\n year period for operating results. \\n \\n 29Table of Contents \\n \\n Guidance We provided guidance on February 6, 2025, in our earnings release furnished on Form 8-K as set forth below. These forward-looking statements reflect \\n \\n Amazon.com\\u2019s expectations as of February 6, 2025, and are subject to substantial uncertainty.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Bedrock agent runtime client to interact with the Bedrock service\n",
    "bedrock_agent_runtime = boto3.client(\"bedrock-agent-runtime\", region_name=variables[\"regionName\"])\n",
    "\n",
    "# Define the query to retrieve relevant documents from the knowledge base\n",
    "query = \"What were net incomes of Amazon in 2022, 2023 and 2024?\" \n",
    "\n",
    "# Use the Bedrock agent runtime to retrieve relevant documents from the knowledge base\n",
    "relevant_documents_os = bedrock_agent_runtime.retrieve(\n",
    "    retrievalQuery= {\n",
    "        'text': query  # The text query for retrieving documents\n",
    "    },\n",
    "    knowledgeBaseId=kb['knowledgeBaseId'],  # The knowledge base ID to search within\n",
    "    retrievalConfiguration= {\n",
    "        'vectorSearchConfiguration': {\n",
    "            'numberOfResults': 3  # Fetch the top 3 documents that closely match the query\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Return the relevant documents found for the query\n",
    "print(json.dumps([i[\"content\"][\"text\"] for i in relevant_documents_os[\"retrievalResults\"]], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea0327",
   "metadata": {},
   "source": [
    "> **Note**: After creating the knowledge base, you can explore its details and settings in the Amazon Bedrock console. This gives you a more visual interface to understand how the knowledge base is structured.\n",
    "> \n",
    "> **[➡️ View your Knowledge Bases in the AWS Console](https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/knowledge-bases)**\n",
    ">\n",
    "> In the console, you can:\n",
    "> - See all your knowledge bases in one place\n",
    "> - View ingestion status and statistics\n",
    "> - Test queries through the built-in chat interface\n",
    "> - Modify settings and configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
